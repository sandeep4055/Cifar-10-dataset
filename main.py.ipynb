{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f739ac8",
   "metadata": {},
   "source": [
    "# Comparing ANN with CNN using cifar 10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bb5450",
   "metadata": {},
   "source": [
    "# Cifar 10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15f9747",
   "metadata": {},
   "source": [
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class.\n",
    "\n",
    "Here are the classes in the dataset, as well as 10 random images from each:\n",
    "#### Image \n",
    "![](image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa000933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets,layers,models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82e03fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 177s 1us/step\n"
     ]
    }
   ],
   "source": [
    "#loading dataset and storing in variables\n",
    "(x_train,y_train),(x_test,y_test) = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9525d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (10000, 32, 32, 3), (50000, 1), (10000, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#size of dataset\n",
    "x_train.shape ,x_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05331e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting 2d array to 1d array\n",
    "y_train = y_train.reshape(-1,)\n",
    "y_test = y_test.reshape(-1,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a683f1f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6, 9, 9, 4, 1, 1, 2, 7, 8], dtype=uint8),\n",
       " array([3, 8, 8, ..., 5, 1, 7], dtype=uint8))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:9],y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccb8508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes present in dataset\n",
    "classes = [\"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "195a29dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to plot image \n",
    "def plot_image(x, y, index):\n",
    "    plt.figure(figsize = (15,2))\n",
    "    plt.imshow(x[index])\n",
    "    plt.xlabel(classes[y[index]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9382c354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_image(x_train,y_train,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0543dbc5",
   "metadata": {},
   "source": [
    "### Normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9253ece6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it sets the input value between 0 & 1\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2321b6b3",
   "metadata": {},
   "source": [
    "## ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c633f2c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 64s 40ms/step - loss: 1.8125 - accuracy: 0.3554\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 65s 41ms/step - loss: 1.6226 - accuracy: 0.4269\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 1.5400 - accuracy: 0.4588\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 1.4810 - accuracy: 0.4783\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 1.4342 - accuracy: 0.4970\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x265c02cc5f8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ann = models.Sequential([\n",
    "        layers.Flatten(input_shape=(32,32,3)),\n",
    "        layers.Dense(3000, activation='relu'),\n",
    "        layers.Dense(1000, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')    \n",
    "    ])\n",
    "\n",
    "ann.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "ann.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cc81e0",
   "metadata": {},
   "source": [
    "## ConfusionMatrix and Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae9150c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.53      0.59      0.56      1000\n",
      "  automobile       0.63      0.58      0.61      1000\n",
      "        bird       0.44      0.24      0.31      1000\n",
      "         cat       0.43      0.19      0.26      1000\n",
      "        deer       0.48      0.34      0.40      1000\n",
      "         dog       0.45      0.34      0.39      1000\n",
      "        frog       0.41      0.74      0.53      1000\n",
      "       horse       0.49      0.62      0.55      1000\n",
      "        ship       0.53      0.68      0.59      1000\n",
      "       truck       0.53      0.58      0.55      1000\n",
      "\n",
      "    accuracy                           0.49     10000\n",
      "   macro avg       0.49      0.49      0.47     10000\n",
      "weighted avg       0.49      0.49      0.47     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "import numpy as np\n",
    "y_pred = ann.predict(x_test)\n",
    "y_pred_classes = [np.argmax(element) for element in y_pred]\n",
    "\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_classes,target_names = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6e5d343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[586  33  44   3  24  12  39  38 179  42]\n",
      " [ 46 584   3  10  11   9  28  39 105 165]\n",
      " [ 95  28 241  49 106  82 234 105  42  18]\n",
      " [ 58  29  43 186  38 179 245  98  41  83]\n",
      " [ 69  16  81  18 344  38 245 137  33  19]\n",
      " [ 33  21  54 103  58 342 183 125  42  39]\n",
      " [ 16  11  26  19  65  27 745  50  20  21]\n",
      " [ 40  14  35  31  49  47  56 624  32  72]\n",
      " [118  56  11   6  11  17  25  22 679  55]\n",
      " [ 47 138   5  12  10  15  38  43 114 578]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ca44e6",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7eb0fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.Sequential([\n",
    "    layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    \n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b482aefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c38d1974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 22s 13ms/step - loss: 1.4934 - accuracy: 0.4611\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 1.1524 - accuracy: 0.5958\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 1.0156 - accuracy: 0.6453\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.9296 - accuracy: 0.6798\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 0.8654 - accuracy: 0.69900s - loss: 0.8\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.8124 - accuracy: 0.7189\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.7675 - accuracy: 0.7334\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.7205 - accuracy: 0.7496\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.6796 - accuracy: 0.7637\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.6471 - accuracy: 0.7730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x26559055da0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42a4a510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    airplane       0.66      0.81      0.73      1000\n",
      "  automobile       0.83      0.80      0.81      1000\n",
      "        bird       0.60      0.59      0.60      1000\n",
      "         cat       0.61      0.39      0.47      1000\n",
      "        deer       0.57      0.76      0.65      1000\n",
      "         dog       0.59      0.63      0.61      1000\n",
      "        frog       0.83      0.76      0.79      1000\n",
      "       horse       0.73      0.76      0.75      1000\n",
      "        ship       0.80      0.77      0.79      1000\n",
      "       truck       0.83      0.74      0.78      1000\n",
      "\n",
      "    accuracy                           0.70     10000\n",
      "   macro avg       0.71      0.70      0.70     10000\n",
      "weighted avg       0.71      0.70      0.70     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "import numpy as np\n",
    "y_pred = cnn.predict(x_test)\n",
    "y_pred_classes = [np.argmax(element) for element in y_pred]\n",
    "\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_classes,target_names = classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "510874c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.9182 - accuracy: 0.6995\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9182299971580505, 0.6995000243186951]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabd42ae",
   "metadata": {},
   "source": [
    "#### By seeing the accuracy of the models we can clearly say that CNN gives much better results than ANN while dealing with <br>\n",
    "#### image models & also the ANN takes more computational power but it is compromised in CNN due to maxpooling layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d21f78d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
